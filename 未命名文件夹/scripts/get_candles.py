import math
import os
import sys
from datetime import datetime, timedelta, timezone

import pandas as pd
from loguru import logger

# å…è®¸ä»é¡¹ç›®æ ¹ç›®å½•å¯¼å…¥æ¨¡å—
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
REPO_ROOT = os.path.dirname(PROJECT_ROOT)
sys.path.append(PROJECT_ROOT)
sys.path.append(REPO_ROOT)

from oandapyV20 import API
import oandapyV20.endpoints.instruments as instruments
from shared.utils.config import OANDA_TOKEN  # ç¡®ä¿è¿™é‡Œèƒ½æ‹¿åˆ° token

# æ—¥å¿—
logger.remove()
logger.add(sys.stderr, level="INFO", format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level}</level> | {message}")

def normalize_to_oanda(symbol: str) -> str:
    """
    å°†ç”¨æˆ·å‹å¥½çš„äº¤æ˜“å¯¹æ ¼å¼è½¬æ¢ä¸ºOANDAæ ¼å¼ï¼Œä¾‹å¦‚ï¼š
    'eurusd', 'EUR-USD', 'eur_usd' -> 'EUR_USD'
    """
    s = symbol.upper().replace("-", "_").replace(" ", "").replace("/", "_")
    # å¦‚æœå·²ç»æ˜¯æ­£ç¡®æ ¼å¼ï¼Œç›´æ¥è¿”å›
    if "_" in s and len(s) == 7:
        return s
    # å°è¯•æ‹†åˆ†ä¸ºä¸¤éƒ¨åˆ†
    if len(s) == 6:
        return s[:3] + "_" + s[3:]
    return s

def default_out_csv(project_root: str, instrument: str, granularity: str) -> str:
    """
    æ ¹æ®äº¤æ˜“å¯¹å’Œæ—¶é—´ç²’åº¦ç”Ÿæˆé»˜è®¤è¾“å‡ºè·¯å¾„ï¼Œå¦‚ï¼š
    data/raw/EURUSD_H1.csv
    """
    fname = f"{instrument.replace('_','')}_{granularity}.csv"
    raw_dir = os.path.join(project_root, "data", "raw")
    os.makedirs(raw_dir, exist_ok=True)
    return os.path.join(raw_dir, fname)

def _bars_per_day(granularity: str) -> float:
    """
    Rough estimate of bars per day forå¸¸è§ OANDA ç²’åº¦ã€‚
    ç”¨äºæ ¹æ® count æ¨ç®—éœ€è¦æ‹‰å–çš„å¤©æ•°ã€‚
    """
    granularity = granularity.upper()
    seconds_map = {
        "S5": 5,
        "S10": 10,
        "S15": 15,
        "S30": 30,
        "M1": 60,
        "M2": 120,
        "M4": 240,
        "M5": 300,
        "M10": 600,
        "M15": 900,
        "M30": 1800,
        "H1": 3600,
        "H2": 7200,
        "H3": 10800,
        "H4": 14400,
        "H6": 21600,
        "H8": 28800,
        "H12": 43200,
        "D": 86400,
        "W": 86400 * 5,
        "M": 86400 * 21,
    }
    seconds = seconds_map.get(granularity, 3600)
    if seconds <= 0:
        return 24
    return max(86400 / seconds, 1)


def get_candles(symbol="EUR_USD", granularity="H1", start_days_ago=365, target_count: int | None = None) -> pd.DataFrame:
    """
    å¾ªç¯æŠ“å– OANDA å†å²Kçº¿ï¼ˆé»˜è®¤è¿‡å»ä¸€å¹´ï¼‰ï¼Œè‡ªåŠ¨åˆ†é¡µæ‹¼æ¥ã€‚
    """
    if not OANDA_TOKEN:
        raise RuntimeError("OANDA_TOKEN ä¸ºç©ºï¼Œè¯·åœ¨ utils/config.py é…ç½®æˆ–é€šè¿‡ç¯å¢ƒå˜é‡æä¾›ã€‚")

    client = API(access_token=OANDA_TOKEN)

    end = datetime.now(timezone.utc)
    start = end - timedelta(days=start_days_ago)
    cur = start
    all_rows = 0
    parts = []

    logger.info(f"å¼€å§‹ä¸‹è½½ {symbol} {granularity}ï¼ˆè¿‡å» {start_days_ago} å¤©ï¼‰")

    # æ¯æ¬¡æŠ“ 20 å¤©ï¼ˆH1 â‰ˆ 480 æ ¹ï¼‰ï¼Œé¿å…å•æ¬¡æ•°æ®è¿‡å¤§
    step = timedelta(days=20)

    while cur < end:
        to_ts = min(cur + step, end)
        params = {
            "granularity": granularity,
            "price": "M",
            "from": cur.isoformat(),
            "to": to_ts.isoformat(),
        }
        r = instruments.InstrumentsCandles(instrument=symbol, params=params)
        try:
            client.request(r)
        except Exception as e:
            logger.error(f"è¯·æ±‚å¤±è´¥ {cur} ~ {to_ts}: {e}")
            break

        candles = r.response.get("candles", [])
        if not candles:
            logger.warning(f"åŒºé—´æ— æ•°æ®ï¼š{cur} ~ {to_ts}")
            cur = to_ts
            continue

        data = [{
            "time": c["time"],
            "open": float(c["mid"]["o"]),
            "high": float(c["mid"]["h"]),
            "low":  float(c["mid"]["l"]),
            "close":float(c["mid"]["c"]),
            "volume": c["volume"]
        } for c in candles if c.get("complete")]

        if data:
            df_part = pd.DataFrame(data)
            parts.append(df_part)
            all_rows += len(df_part)
            logger.info(f"æŠ“å–åŒºé—´ {cur:%Y-%m-%d} ~ {to_ts:%Y-%m-%d} è¡Œæ•°={len(df_part)}ï¼Œç´¯è®¡={all_rows}")

        cur = to_ts  # æ¨è¿›çª—å£

        if target_count and all_rows >= target_count:
            logger.info(f"å·²æ»¡è¶³ç›®æ ‡æ¡æ•° {target_count}ï¼Œåœæ­¢æŠ“å–ã€‚")
            break

    if not parts:
        logger.warning("æ²¡æœ‰è·å–åˆ°ä»»ä½•æ•°æ®ã€‚")
        return pd.DataFrame()

    df = pd.concat(parts, ignore_index=True)
    df["time"] = pd.to_datetime(df["time"])
    df = df.sort_values("time").drop_duplicates(subset=["time"]).reset_index(drop=True)
    if target_count:
        df = df.tail(target_count).reset_index(drop=True)

    logger.info(f"âœ… ä¸‹è½½å®Œæˆï¼šæ€»è®¡ {len(df)} è¡Œï¼ˆ{df['time'].min()} ~ {df['time'].max()}ï¼‰")
    return df

def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--symbol", default="EUR_USD")
    parser.add_argument("--granularity", default="H1")
    parser.add_argument("--days", type=int, default=365, help="å‘å‰å›æº¯å¤©æ•°")
    parser.add_argument("--count", type=int, default=None, help="ï¼ˆå¯é€‰ï¼‰éœ€è¦çš„ K çº¿æ•°é‡ï¼Œè„šæœ¬ä¼šæ ¹æ®ç²’åº¦ä¼°ç®—å¤©æ•°ï¼ŒæŠ“å¤Ÿåæˆªæ–­")
    parser.add_argument("--out", "--output", dest="out", default=None)
    args = parser.parse_args()

    # è§„èŒƒåŒ–äº¤æ˜“å¯¹æ ¼å¼
    args.symbol = normalize_to_oanda(args.symbol)

    # è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºè·¯å¾„ï¼ˆå¦‚æœæœªæŒ‡å®šï¼‰
    if args.out is None:
        args.out = default_out_csv(PROJECT_ROOT, args.symbol, args.granularity)

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(args.out), exist_ok=True)

    target_count = args.count if args.count and args.count > 0 else None
    if target_count:
        est_days = math.ceil(target_count / _bars_per_day(args.granularity)) + 5
        if est_days > args.days:
            logger.info(f"æ ¹æ® count={target_count} ä¼°ç®—éœ€è¦ {est_days} å¤©æ•°æ®ï¼ˆåŸ days={args.days}ï¼‰ï¼Œå·²è‡ªåŠ¨æ‰©å±•ã€‚")
            args.days = est_days

    try:
        df = get_candles(args.symbol, args.granularity, args.days, target_count=target_count)
    except Exception as e:
        logger.exception(f"ä¸‹è½½å¤±è´¥ï¼š{e}")
        sys.exit(1)

    if df.empty:
        logger.warning("ç»“æœä¸ºç©ºï¼Œæœªä¿å­˜ã€‚")
        sys.exit(2)

    df.to_csv(args.out, index=False)
    logger.info(f"ğŸ“¦ å·²ä¿å­˜åˆ°ï¼š{args.out}")
    # æ–¹ä¾¿ä½ è‚‰çœ¼ç¡®è®¤
    logger.info(f"å°¾éƒ¨é¢„è§ˆï¼š\n{df.tail(3).to_string(index=False)}")

if __name__ == "__main__":
    main()
